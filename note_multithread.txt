P3:
Single-thread Program on Computer with Single Processor
- A program runs on a single processor
+ The program's instruction are loaded from memory
+ The instruction are executed on the processor
- Registers store information needed to execute the current instruction
+ Stack pointer
+ operand argument
+ etc
- Data is loaded from memory into processor registers as needed
- If modified, the new value is the written back to memory
_ implemented by "Time slicing"
- Each thread runs on the CPU for a short time eg
+ Thread A starts, runs for a short period, then pauses
+ Thread B starts, runs for a short period, then pauses
+ Thread C starts, runs for a short period, then pauses
+ Thread B runs again from where it left off, then pauses
+ Thread c runs again from where it left off, then pauses
- This is doen very quickly ====> The threads appear to run concurrently

Thread Scheduler
- A Scheculer controls how threads execute
+ Similar to the operating system's scheduler for processes
- Pre-emtive task switching
+ A thread can run for certain time
+ The scheduler will interupt the thread when it has used up ist time slot
+ Another thread can then run
+ The scheduler will make interupted thread "sleep"

Thread Scheduling
- Threads may start in any order
- A thread may be interupted at any time
- A thread may be restarted at any time
- While a thread is sleeping, another thread may run
+ This can run the same code as the inactive thread
+ It ca access data which it shares with the inactive thread
- The execution of the threads is interleaved
+ Thread B starts and is interupted
+ Thread A starts and is interupted
.....

Disadvantages of Time slicing
- Requires "context switch"
- Save the processor state for the current thread
+ current values of processor registers
+ Program's instruction pointer
+ etc
- Load the saved processor state for the next thread
+ Values of processor registers when stoppped, etc
+ May also have to reload the thread's instructions and data
- The processor cannot execute any instructions during a context switch

Computer with single processor and Cache
Cache
- CPUs became much faster at processing instructions
- However, RAM access speed did not improve very much
- The CPU could not process instructions during data transfers
+ The CPU spent  a lot of time waiting for RAM to respond
+ Memory latency became a problem
- Computers started using small amount of "cache" memory

Cache memory
- Cache memory
 + Physically close to the CPU
 + Stores copies of current and recently used data
 + Reduces the time spent communicating with main memory
 - Uses "static" RAM
 + This is faster than the "dynamic" RAM used in main memory
 + More expensive
 + Uses more power
 + usually much smaller than main memory
 
 Cache Fetch
 - The CPU wants to fetch data
 - Does the cache have a copy of the data?
 - Yes
 + There is a "cache hit"
 + The CPU uses that copy
 - No
 + There is a "cache miss"
 + The data is fetched from main memory
 
 Cache write
 - The CPU wants to store data
 - It writes the data to the cache
 - The data in the cache is written to main memory
 + The CPU can continue working wile this happens
 
 Cache Controller
 - The process is managed by a "cache controller"
 - The data is transferred in fixed-size blocks
 + known as "cache lines"
 + Typically 64 bytes on modern hardware
 - Each cache line relates to an address in main memory
 
 
 Computer with Muliple Processor
 - Multiple sockets
 + 2 or more processor chips in the computer
 - Multiple processor cores
 + several processors within the same silicon chip
 - Hyperthreads
 + Duplicate some of the circuitry within a processor core
 + enough to run a separeted thread, with its own execution stack
 
 Memory
 - Processor speed has increased hugely
 - Memory performance has not kept up
 - Designers had to find new ways to improve performance
 + Many more registers for storing data and code in the processor
 + Additional caches between processors and main memory
 
 Multiple Levels of Cache
 - Level 1
 + Private to each processor core
 + As close to the core as possible
 - Level 2
 + Ussally private to each core
 - Level 3
 + Shared by all the cores on the same socket
 
 Cache Controller
 - Coordinates the caches
 + the same data should have the same value in call caches
 + the same data should have the same value on all cores
 + "Cache coherency"
 
 - Monitors caches for data changes 
 + A core modifies data in its level 1 cache
 + The data is updated in the core's level 2 cache
 + The data is updated in the level 3 cache
 + The data is updated in the over cores's caches
 
 Optimization
 - Pre-fetcher
 + Looks at incoming instructions
 + Fetches data before it is needed
 - Store buffer
 + This is betwwen the core and the level 1 cache
 + Modified data is written to this buffer
 - The core can proceed to the next instruction
 + Does not need to wait for the L1 cache
 - These optimiztions provide huge improvements
 + Avoid blocking the core when there is a cache miss
 
 
 Synchronization Issues
  Synchronization Issues
 - Different threads execute on different cores
 - They may share data
 - This can cause synchronization issues
 
 Issues
 - core 1's thread modifies the shared data
 - core1 writes the new value to its store buffer
 - core2's thread wants to use the shared data
 - core 2 pre-fetches the share data, or loads it from cache
 - core 2 gets the old value
 - core 2's thread does it computation, using the old value
 - core 1's store buffer writes the new value to cache
 ___________________________________________________________________________________________
 P2
 
 System Thread Interface
 System Thread Interface
 - std::thread use the system's thread implementation
 - We may need to use the thread implementation directly
 - Some functionality is not available in standard C++
 - Thread priority
 + Give a thread higher or lower share of processor time
 - Thread affinity
 + "Pin" a thread on a specific processor core
 
